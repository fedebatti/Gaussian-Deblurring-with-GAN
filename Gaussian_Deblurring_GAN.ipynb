{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 29835.922001,
      "end_time": "2020-08-27T03:48:26.169701",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-08-26T19:31:10.247700",
      "version": "2.1.0"
    },
    "colab": {
      "name": "Deep Learning Project Activity.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEKaVdhGyvQN"
      },
      "source": [
        "# Deep Learning project work, Image Deblurring with WGANs\n",
        "\n",
        "Federico Battistella 0000926542"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project we're going to implement a GAN to perform image deblurring, in this case the dataset CIFAR10 has been selected and the type of blurring applied is a random Gaussian blur.\n",
        "This projet is based on the paper \"DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks\" by Orest Kupyn et al.\n",
        "\n",
        "https://arxiv.org/pdf/1711.07064.pdf"
      ],
      "metadata": {
        "id": "uuh4hkXweU4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The WGAN (Wasserstein GAN) model, is based on the Wasserstein loss.\n",
        "The WGAN is an extension of the traditional GANs which manage to stabilize the training of the GANs which usually is very long and difficult to reach the convergency.\n",
        "The reason GANs are difficult to train is that the architecture involves the simultaneous training of a generator and a discriminator model in a zero-sum game. Stable training requires finding and maintaining an equilibrium between the capabilities of the two models.\n",
        "Instead of using a discriminator to classify or predict the probability of generated images of being real or fake, the WGAN changes or replaces the discriminator model with a critic that scores the realness or fakeness of a given image.\n",
        "WGAN changes or replaces the discriminator model with a critic that scores the realness or fakeness of a given image.\n",
        "\n",
        "This change is motivated by a mathematical argument that training the generator should seek a minimization of the distance between the distribution of the data observed in the training dataset and the distribution observed in generated examples."
      ],
      "metadata": {
        "id": "waHcUf2c6usm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:32:45.534523Z",
          "iopub.status.busy": "2020-08-26T19:32:45.533491Z",
          "iopub.status.idle": "2020-08-26T19:32:45.536587Z",
          "shell.execute_reply": "2020-08-26T19:32:45.536033Z"
        },
        "id": "wzkaX0X_gzfK",
        "papermill": {
          "duration": 0.323597,
          "end_time": "2020-08-26T19:32:45.536704",
          "exception": false,
          "start_time": "2020-08-26T19:32:45.213107",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Setting Google Drive for Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# !pip install tensorflow\n",
        "# !pip install keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "XfMFb3B3oSRZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:32:46.182628Z",
          "iopub.status.busy": "2020-08-26T19:32:46.181747Z",
          "iopub.status.idle": "2020-08-26T19:33:07.290063Z",
          "shell.execute_reply": "2020-08-26T19:33:07.289167Z"
        },
        "id": "veuqUb6Sz6Qy",
        "papermill": {
          "duration": 21.428795,
          "end_time": "2020-08-26T19:33:07.290255",
          "exception": false,
          "start_time": "2020-08-26T19:32:45.861460",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "import tqdm\n",
        "import datetime\n",
        "import math\n",
        "import os\n",
        "import gc\n",
        "import h5py\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from skimage.metrics import structural_similarity\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.backend as K\n",
        "\n",
        "from keras import losses\n",
        "from keras import backend\n",
        "from keras.backend import image_data_format\n",
        "#from keras.backend import normalize_data_format\n",
        "from keras.layers import InputSpec\n",
        "from tensorflow.keras.layers import Layer\n",
        "from keras.utils import conv_utils\n",
        "from keras.models import Model, load_model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.layers.merge import Add\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.initializers import RandomNormal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eager execution is required to train the model, some modules used are not compatible with tf2 graph execution"
      ],
      "metadata": {
        "id": "o9BGwEgCvtr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "VruIXuUJIYWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test if the GPU device is available for training"
      ],
      "metadata": {
        "id": "ADpaYm8Fvjcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU TEST\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "id": "OFSc_iFQjfHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:33:07.876496Z",
          "iopub.status.busy": "2020-08-26T19:33:07.875612Z",
          "iopub.status.idle": "2020-08-26T19:33:07.879340Z",
          "shell.execute_reply": "2020-08-26T19:33:07.878838Z"
        },
        "id": "KgCZ0g9TyePN",
        "papermill": {
          "duration": 0.297693,
          "end_time": "2020-08-26T19:33:07.879457",
          "exception": false,
          "start_time": "2020-08-26T19:33:07.581764",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Parameters\n",
        "\n",
        "image_shape = (32, 32, 3)\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "n_blocks_generator = 9\n",
        "n_layers_discriminator = 3\n",
        "len_all = 50000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v68ff1gNzKA2"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each residual block starts with a padding to keep the dim as the input after the convolutions, then we find a batch normalization layer that alter the distribution of the datas to make them having mean = 0 and standard deviation = 1.\n",
        "Then we find a dropout and a residual connection in the end that just performs a summation between input and output of the block, making it easier for the network to learn the identity function without adding computational complexity nor additional parameters."
      ],
      "metadata": {
        "id": "dkYsUcp9m92U"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:33:08.472037Z",
          "iopub.status.busy": "2020-08-26T19:33:08.470152Z",
          "iopub.status.idle": "2020-08-26T19:33:08.472776Z",
          "shell.execute_reply": "2020-08-26T19:33:08.473251Z"
        },
        "id": "SomdEIlxyecO",
        "papermill": {
          "duration": 0.307563,
          "end_time": "2020-08-26T19:33:08.473374",
          "exception": false,
          "start_time": "2020-08-26T19:33:08.165811",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def res_block(input, filters, kernel_size=(3, 3), strides=(1, 1), use_dropout=True):\n",
        "    # Resnet Block \n",
        "    init = RandomNormal(mean=0.0, stddev=0.0025)\n",
        "    \n",
        "    block = ReflectionPadding2D((1, 1))(input)\n",
        "    block = Conv2D(filters=filters,\n",
        "               kernel_size=kernel_size,\n",
        "               strides=strides, kernel_initializer=init)(block)\n",
        "    block = BatchNormalization()(block)\n",
        "    block = Activation('relu')(block)\n",
        "\n",
        "    if use_dropout:\n",
        "        block = Dropout(0.5)(block)\n",
        "\n",
        "    block = ReflectionPadding2D((1, 1))(block)\n",
        "    block = Conv2D(filters=filters,\n",
        "               kernel_size=kernel_size,\n",
        "               strides=strides, kernel_initializer=init)(block)\n",
        "    block = BatchNormalization()(block)\n",
        "\n",
        "    merged = Add()([input, block])\n",
        "    return merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reflection 2D padding is applied to balance the following convolutional layer so to maintain the dimension of the input image. Reflection 2d Padding reflects the pixel values around the edge, and this enables us to obtain padded inputs that are still part of the same data distribution as the input image."
      ],
      "metadata": {
        "id": "Xiffb1FxIBJr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:33:09.295987Z",
          "iopub.status.busy": "2020-08-26T19:33:09.294887Z",
          "iopub.status.idle": "2020-08-26T19:33:09.304999Z",
          "shell.execute_reply": "2020-08-26T19:33:09.306201Z"
        },
        "id": "bMzHZ9wE07D3",
        "papermill": {
          "duration": 0.502138,
          "end_time": "2020-08-26T19:33:09.306455",
          "exception": false,
          "start_time": "2020-08-26T19:33:08.804317",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def spatial_reflection_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n",
        "    \"\"\"\n",
        "    Used to pad the 2nd and 3rd dimensions of a 4D tensor.\n",
        "\n",
        "    Input tensor -> x\n",
        "    Padding dimension -> padding\n",
        "    Format of the data ('channels_last', 'channels_first') -> data_format\n",
        "    \"\"\"\n",
        "    assert len(padding) == 2\n",
        "    assert len(padding[0]) == 2\n",
        "    assert len(padding[1]) == 2\n",
        "\n",
        "    if data_format is None:\n",
        "        data_format = image_data_format()\n",
        "    \n",
        "    if data_format not in {'channels_first', 'channels_last'}:\n",
        "        raise ValueError('Unknown data_format ' + str(data_format))\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        pattern = [[0, 0],\n",
        "                   [0, 0],\n",
        "                   list(padding[0]),\n",
        "                   list(padding[1])]\n",
        "    else:\n",
        "        pattern = [[0, 0],\n",
        "                   list(padding[0]), list(padding[1]),\n",
        "                   [0, 0]]\n",
        "    return tf.pad(x, pattern, \"REFLECT\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_data_format(value):\n",
        "    if value is None:\n",
        "        value = image_data_format()\n",
        "    data_format = value.lower()\n",
        "    if data_format not in {'channels_first', 'channels_last'}:\n",
        "        raise ValueError('The `data_format` argument must be one of '\n",
        "                         '\"channels_first\", \"channels_last\". Received: ' +\n",
        "                         str(value))\n",
        "    return data_format"
      ],
      "metadata": {
        "id": "Vu9dUMdYANCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:33:10.080034Z",
          "iopub.status.busy": "2020-08-26T19:33:10.079226Z",
          "iopub.status.idle": "2020-08-26T19:33:10.083029Z",
          "shell.execute_reply": "2020-08-26T19:33:10.082553Z"
        },
        "id": "HZKAuYCO1GQV",
        "papermill": {
          "duration": 0.375071,
          "end_time": "2020-08-26T19:33:10.083140",
          "exception": false,
          "start_time": "2020-08-26T19:33:09.708069",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class ReflectionPadding2D(Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 padding=(1, 1),\n",
        "                 data_format=None,\n",
        "                 **kwargs):\n",
        "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "        self.data_format = normalize_data_format(data_format)\n",
        "        if isinstance(padding, int):\n",
        "            self.padding = ((padding, padding), (padding, padding))\n",
        "        elif hasattr(padding, '__len__'):\n",
        "            if len(padding) != 2:\n",
        "                raise ValueError('`padding` should have two elements. '\n",
        "                                 'Found: ' + str(padding))\n",
        "            height_padding = conv_utils.normalize_tuple(padding[0], 2,\n",
        "                                                        '1st entry of padding')\n",
        "            width_padding = conv_utils.normalize_tuple(padding[1], 2,\n",
        "                                                       '2nd entry of padding')\n",
        "            self.padding = (height_padding, width_padding)\n",
        "        else:\n",
        "            raise ValueError('`padding` should be either an int, '\n",
        "                             'a tuple of 2 ints '\n",
        "                             '(symmetric_height_pad, symmetric_width_pad), '\n",
        "                             'or a tuple of 2 tuples of 2 ints '\n",
        "                             '((top_pad, bottom_pad), (left_pad, right_pad)). '\n",
        "                             'Found: ' + str(padding))\n",
        "        self.input_spec = InputSpec(ndim=4)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            if input_shape[2] is not None:\n",
        "                rows = input_shape[2] + self.padding[0][0] + self.padding[0][1]\n",
        "            else:\n",
        "                rows = None\n",
        "            if input_shape[3] is not None:\n",
        "                cols = input_shape[3] + self.padding[1][0] + self.padding[1][1]\n",
        "            else:\n",
        "                cols = None\n",
        "            return (input_shape[0],\n",
        "                    input_shape[1],\n",
        "                    rows,\n",
        "                    cols)\n",
        "        elif self.data_format == 'channels_last':\n",
        "            if input_shape[1] is not None:\n",
        "                rows = input_shape[1] + self.padding[0][0] + self.padding[0][1]\n",
        "            else:\n",
        "                rows = None\n",
        "            if input_shape[2] is not None:\n",
        "                cols = input_shape[2] + self.padding[1][0] + self.padding[1][1]\n",
        "            else:\n",
        "                cols = None\n",
        "            return (input_shape[0],\n",
        "                    rows,\n",
        "                    cols,\n",
        "                    input_shape[3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return spatial_reflection_2d_padding(inputs,\n",
        "                                             padding=self.padding,\n",
        "                                             data_format=self.data_format)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'padding': self.padding,\n",
        "                  'data_format': self.data_format}\n",
        "        base_config = super(ReflectionPadding2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator model architecture"
      ],
      "metadata": {
        "id": "WFyY6pqjxb-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generator architecture consists in:\n",
        "-\n",
        "*   Downsampling\n",
        "*   Residual blocks X9\n",
        "*   Upsampling"
      ],
      "metadata": {
        "id": "stbVMbdpklan"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:33:10.677887Z",
          "iopub.status.busy": "2020-08-26T19:33:10.675761Z",
          "iopub.status.idle": "2020-08-26T19:33:10.678663Z",
          "shell.execute_reply": "2020-08-26T19:33:10.679130Z"
        },
        "id": "LmPEs1awvG1-",
        "papermill": {
          "duration": 0.306434,
          "end_time": "2020-08-26T19:33:10.679252",
          "exception": false,
          "start_time": "2020-08-26T19:33:10.372818",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def generator_model():\n",
        "    init = RandomNormal(mean=0.0, stddev=0.0025)\n",
        "    inputs = Input(shape=image_shape)\n",
        "\n",
        "    x = ReflectionPadding2D((3, 3))(inputs)\n",
        "    x = Conv2D(filters=ngf, kernel_size=(7, 7), padding='valid', kernel_initializer=init)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    n_downsampling = 2\n",
        "    for i in range(n_downsampling):\n",
        "        mult = 2**i\n",
        "        x = Conv2D(filters=ngf*mult*2, kernel_size=(3, 3), strides=2, padding='same', kernel_initializer=init)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "    \n",
        "    mult = 2**n_downsampling\n",
        "    for i in range(n_blocks_generator):\n",
        "        x = res_block(x, ngf*mult, use_dropout=True)\n",
        "    \n",
        "\n",
        "    for i in range(n_downsampling):\n",
        "        mult = 2**(n_downsampling - i)\n",
        "        x = UpSampling2D()(x)\n",
        "        x = Conv2D(filters=int(ngf * mult / 2), kernel_size=(3, 3), padding='same', kernel_initializer=init)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        \n",
        "\n",
        "    x = ReflectionPadding2D((3, 3))(x)\n",
        "    x = Conv2D(filters=3, kernel_size=(7, 7), padding='valid', kernel_initializer=init)(x)\n",
        "    x = Activation('tanh')(x)\n",
        "    \n",
        "    \n",
        "    outputs = Add()([x, inputs])\n",
        "    outputs = Lambda(lambda z: z/2)(outputs)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='Generator')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminator model architecture"
      ],
      "metadata": {
        "id": "NgHH1YoFyN16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disciminator model is a convolutional patchGAN modified to ouput a critic score instead of the probability for the image of being real or not.\n",
        "The critic model indicates how close is the model distribution to the real distribution.\n",
        "The model is made by several convolutions for downsampling, followed by batch normalizations and leakyRelu as activation funcitons.\n",
        "In the end a dense layer with a linear activation is required to output the score of the critic."
      ],
      "metadata": {
        "id": "MSXI_ghGgFAH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:33:11.278509Z",
          "iopub.status.busy": "2020-08-26T19:33:11.277553Z",
          "iopub.status.idle": "2020-08-26T19:33:11.279956Z",
          "shell.execute_reply": "2020-08-26T19:33:11.280390Z"
        },
        "id": "MQa7LsZ1x0I7",
        "papermill": {
          "duration": 0.308222,
          "end_time": "2020-08-26T19:33:11.280562",
          "exception": false,
          "start_time": "2020-08-26T19:33:10.972340",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def discriminator_model():\n",
        "    # discriminator architecture\n",
        "    init = RandomNormal(mean=0.0, stddev=0.0025)\n",
        "    \n",
        "    inputs = Input(shape=image_shape)\n",
        "\n",
        "    x = Conv2D(filters=ndf, kernel_size=(4, 4), strides=2, padding='same', kernel_initializer=init)(inputs)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    nf_mult = 1\n",
        "    for n in range(n_layers_discriminator):\n",
        "        nf_mult = min(2**n, 8)\n",
        "        x = Conv2D(filters=ndf*nf_mult, kernel_size=(4, 4), strides=2, padding='same', kernel_initializer=init)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    nf_mult = min(2**n_layers_discriminator, 8)\n",
        "    x = Conv2D(filters=ndf*nf_mult, kernel_size=(4, 4), strides=1, padding='same', kernel_initializer=init)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(filters=1, kernel_size=(4, 4), strides=1, padding='same', kernel_initializer=init)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1, activation='linear', kernel_initializer=init)(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=x, name='Discriminator')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model combining generator and discriminator"
      ],
      "metadata": {
        "id": "au_xUMRdht0U"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:33:11.857152Z",
          "iopub.status.busy": "2020-08-26T19:33:11.856237Z",
          "iopub.status.idle": "2020-08-26T19:33:11.858685Z",
          "shell.execute_reply": "2020-08-26T19:33:11.859114Z"
        },
        "id": "ITMFqc4FJrAH",
        "papermill": {
          "duration": 0.29269,
          "end_time": "2020-08-26T19:33:11.859244",
          "exception": false,
          "start_time": "2020-08-26T19:33:11.566554",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def generator_containing_discriminator(generator, discriminator):\n",
        "    inputs = Input(shape=image_shape)\n",
        "    generated_image = generator(inputs)\n",
        "    outputs = discriminator(generated_image)\n",
        "    model = Model(inputs=inputs, outputs=[generated_image, outputs])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDo6HJJDzRlq"
      },
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total loss = Wasserstein_loss + perceptual_loss"
      ],
      "metadata": {
        "id": "p2gLU2qz5Rgn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:33:12.448830Z",
          "iopub.status.busy": "2020-08-26T19:33:12.447806Z",
          "iopub.status.idle": "2020-08-26T19:33:12.449959Z",
          "shell.execute_reply": "2020-08-26T19:33:12.450462Z"
        },
        "id": "IgkoRX6-JwJ8",
        "papermill": {
          "duration": 0.306433,
          "end_time": "2020-08-26T19:33:12.450589",
          "exception": false,
          "start_time": "2020-08-26T19:33:12.144156",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def perceptual_loss(y_true, y_pred):\n",
        "    vgg = VGG16(include_top=False, weights='imagenet', input_shape=image_shape)\n",
        "    loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
        "    loss_model.trainable = False\n",
        "    return K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\n",
        "\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "    return K.mean(y_true*y_pred)\n",
        "\n",
        "def mae_loss(y_true, y_pred):\n",
        "    return K.mean(K.abs(y_true - y_pred))\n",
        "\n",
        "def content_loss(y_true, y_pred):\n",
        "    return 100*perceptual_loss(y_true, y_pred) + 140*mae_loss(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv43WaHLzVLt"
      },
      "source": [
        "## Dataset loading"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset used is CIFAR10, 50000 32x32 RGB images, then a Gaussian Blurring with random kernel size between 1 and 9 is applied to obtain the dataset for the deblurring task"
      ],
      "metadata": {
        "id": "vSEYcq972jWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from matplotlib import pyplot\n",
        "import cv2\n",
        "import random\n",
        "# Loading dataset CIFAR-10\n",
        "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "# Check dataset shapes\n",
        "print('Train: X=%s, y=%s' % (trainX.shape, trainY.shape))\n",
        "print('Test: X=%s, y=%s' % (testX.shape, testY.shape))\n",
        "\n",
        "# Blurring train images\n",
        "trainX_blur = []\n",
        "for i in range(trainX.shape[0]):\n",
        "  size = random.randint(1,9)\n",
        "  kernel = (size, size)\n",
        "  trainX_blur.append(cv2.blur(trainX[i], kernel))\n",
        "\n",
        "# Visual checks\n",
        "trainX_blur = np.array(trainX_blur)\n",
        "print(trainX_blur.shape)\n",
        "\n",
        "for i in range(9):\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(330 + 1 + i)\n",
        "\t# plot raw pixel data\n",
        "\tpyplot.imshow(trainX_blur[i])\n",
        "# show the figure\n",
        "pyplot.show()\n",
        "\n",
        "# Blurring test images\n",
        "testX_blur = []\n",
        "for i in range(testX.shape[0]):\n",
        "  size = random.randint(1,9)\n",
        "  kernel = (size, size)\n",
        "  testX_blur.append(cv2.blur(testX[i], kernel))\n",
        "\n",
        "# Visual checks\n",
        "testX_blur = np.array(testX_blur)\n",
        "print(testX_blur.shape)\n",
        "\n",
        "for i in range(9):\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(330 + 1 + i)\n",
        "\t# plot raw pixel data\n",
        "\tpyplot.imshow(testX_blur[i])\n",
        "# show the figure\n",
        "pyplot.show()\n"
      ],
      "metadata": {
        "id": "OGx-rQKsReoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing applied to the images"
      ],
      "metadata": {
        "id": "v2Krtqec7K72"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:33:13.081898Z",
          "iopub.status.busy": "2020-08-26T19:33:13.081007Z",
          "iopub.status.idle": "2020-08-26T19:33:13.083835Z",
          "shell.execute_reply": "2020-08-26T19:33:13.083276Z"
        },
        "id": "Vlbi9640WzjD",
        "papermill": {
          "duration": 0.344033,
          "end_time": "2020-08-26T19:33:13.083937",
          "exception": false,
          "start_time": "2020-08-26T19:33:12.739904",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def preprocess_image(img):\n",
        "    return (img - 127.5) / 127.5\n",
        "\n",
        "def deprocess_image(img):\n",
        "    return img * 127.5 + 127.5\n",
        "\n",
        "# def load_data(data_type, path):\n",
        "#     with h5py.File(path, 'r') as f:\n",
        "#         data_sharp = f['%s_data_sharp' % data_type][:].astype(np.float16)\n",
        "#         data_sharp = preprocess_image(data_sharp)\n",
        "\n",
        "#         data_blur = f['%s_data_blur' % data_type][:].astype(np.float16)\n",
        "#         data_blur = preprocess_image(data_blur)\n",
        "\n",
        "#         return data_sharp, data_blur\n",
        "\n",
        "def load_data(train, train_blur):\n",
        "  data_sharp = train.astype(np.float16)\n",
        "  data_sharp = preprocess_image(data_sharp)\n",
        "\n",
        "  data_blur = train_blur.astype(np.float16)\n",
        "  data_blur = preprocess_image(data_blur)\n",
        "\n",
        "  return data_sharp, data_blur\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r train.zip dataset/train\n",
        "# !zip -r train_blur.zip dataset/train_blur\n",
        "# from google.colab import files\n",
        "# files.download(\"train.zip\")\n",
        "# files.download(\"train_blur.zip\")"
      ],
      "metadata": {
        "id": "SB8vDY7EFxRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:33:13.674854Z",
          "iopub.status.busy": "2020-08-26T19:33:13.673930Z",
          "iopub.status.idle": "2020-08-26T19:33:13.676915Z",
          "shell.execute_reply": "2020-08-26T19:33:13.676358Z"
        },
        "id": "Um1usUd8J7_j",
        "papermill": {
          "duration": 0.306725,
          "end_time": "2020-08-26T19:33:13.677024",
          "exception": false,
          "start_time": "2020-08-26T19:33:13.370299",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "weights_save_dir =  '/content/gdrive/My Drive/Colab Notebooks/weights'\n",
        "model_save_dir = '/content/gdrive/My Drive/Colab Notebooks/models'\n",
        "model_load_dir = '/content/gdrive/My Drive/Colab Notebooks/models'\n",
        "\n",
        "\n",
        "def save_all_weights(d, g, epoch_number, current_loss):\n",
        "    now = datetime.datetime.now()\n",
        "    save_dir = os.path.join(weights_save_dir, '{}{}'.format(now.month, now.day))\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    g.save_weights(os.path.join(save_dir, 'generator_{}_{}.h5'.format(epoch_number, current_loss)), True)\n",
        "    d.save_weights(os.path.join(save_dir, 'discriminator_{}.h5'.format(epoch_number)), True)\n",
        "\n",
        "def save_models(d, d_on_g):\n",
        "    if not os.path.exists(model_save_dir):\n",
        "        os.makedirs(model_save_dir)\n",
        "    for layer in d.layers[:]:\n",
        "        layer.trainable = True\n",
        "    d.save(os.path.join(model_save_dir, 'discriminator_model.h5'))\n",
        "    for layer in d.layers[:]:\n",
        "        layer.trainable = False\n",
        "    d_on_g.save(os.path.join(model_save_dir, 'combined_model.h5'))\n",
        "    for layer in d.layers[:]:\n",
        "        layer.trainable = True   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVQZAACfzbhN"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:33:14.281131Z",
          "iopub.status.busy": "2020-08-26T19:33:14.280118Z",
          "iopub.status.idle": "2020-08-26T19:33:14.283056Z",
          "shell.execute_reply": "2020-08-26T19:33:14.282500Z"
        },
        "id": "KQu_ozmsJ_fl",
        "papermill": {
          "duration": 0.323353,
          "end_time": "2020-08-26T19:33:14.283166",
          "exception": false,
          "start_time": "2020-08-26T19:33:13.959813",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def train(batch_size, epoch_num, critic_updates=5, load=False):\n",
        "    with tf.device('/device:GPU:0'):\n",
        "      if load: \n",
        "          dis = load_model(os.path.join(model_load_dir, 'discriminator_model.h5'), custom_objects={'wasserstein_loss': wasserstein_loss})\n",
        "          dis_and_gen = load_model(os.path.join(model_load_dir, 'combined_model.h5'), custom_objects={'ReflectionPadding2D': ReflectionPadding2D, 'wasserstein_loss': wasserstein_loss, 'content_loss' : content_loss})\n",
        "          gen = dis_and_gen.get_layer('Generator')\n",
        "          \n",
        "      else:\n",
        "          gen = None\n",
        "          dis = None\n",
        "          gen = generator_model()\n",
        "          dis = discriminator_model()\n",
        "          dis_and_gen = generator_containing_discriminator(gen, dis)\n",
        "\n",
        "          dis_opt = Adam(lr=0.0001, beta_1=0.9)\n",
        "          dis_and_gen_opt = Adam(lr=0.0001, beta_1=0.9)\n",
        "\n",
        "          dis.trainable = True\n",
        "          dis.compile(loss=wasserstein_loss, optimizer=dis_opt)\n",
        "          dis.trainable = False\n",
        "          dis_and_gen.compile(loss=[content_loss, wasserstein_loss], optimizer=dis_and_gen_opt)\n",
        "          dis.trainable = True\n",
        "        \n",
        "      y_train, x_train = load_data(trainX, trainX_blur)\n",
        "      \n",
        "      for epoch in tqdm.tqdm(range(epoch_num)):\n",
        "          \n",
        "          d_losses = []\n",
        "          d_losses_r = []\n",
        "          d_losses_f = []\n",
        "          dis_and_gen_losses = []\n",
        "          num_batches = int(len_all / batch_size)\n",
        "          curr_dataset = 0\n",
        "          \n",
        "          for batch in range(num_batches):        \n",
        "              if batch%100 == 0:\n",
        "                print(f'Epoch {epoch}, iteration: {batch}')\n",
        "              permutated_indexes = np.random.permutation(x_train.shape[0])\n",
        "              batch_indexes = permutated_indexes[0:batch_size]\n",
        "              image_blur_batch = x_train[batch_indexes]\n",
        "              image_sharp_batch = y_train[batch_indexes]\n",
        "              \n",
        "              positive_labels = np.ones((batch_size, 1))\n",
        "              negative_labels = -np.ones((batch_size, 1))\n",
        "              batch_and_labels = [image_sharp_batch, positive_labels]\n",
        "\n",
        "              # Discrimintor training\n",
        "              gen_imgs = gen.predict(image_blur_batch)\n",
        "              for _ in range(critic_updates):\n",
        "                  d_loss_real = dis.train_on_batch(image_sharp_batch, positive_labels)\n",
        "                  d_loss_fake = dis.train_on_batch(gen_imgs, negative_labels)\n",
        "                  d_losses_r.append(d_loss_real)\n",
        "                  d_losses_f.append(d_loss_fake)\n",
        "                  d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "                  d_losses.append(d_loss)\n",
        "                  # Weights clipping to [-0.01,0.01] to enforce the Lipschitz constraint\n",
        "                  for l in dis.layers:\n",
        "                      weights = l.get_weights()\n",
        "                      weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
        "                      l.set_weights(weights)\n",
        "\n",
        "              # Generator Training \n",
        "              dis.trainable = False\n",
        "              dis_and_gen_loss = dis_and_gen.train_on_batch(image_blur_batch, batch_and_labels)\n",
        "              dis_and_gen_losses.append(dis_and_gen_loss)\n",
        "              dis.trainable = True\n",
        "              \n",
        "\n",
        "          print(f\"{epoch} [D loss r: {np.mean(d_losses_r)} | D loss f: {np.mean(d_losses_f)} | D loss: {np.mean(d_losses)}] [G loss: {np.mean(dis_and_gen_losses)}]\")\n",
        "          with open('/content/gdrive/My Drive/Colab Notebooks/logs/log.txt', 'a+') as f:\n",
        "              f.write(f\"{epoch} [D loss r: {np.mean(d_losses_r)} | D loss f: {np.mean(d_losses_f)} | D loss: {np.mean(d_losses)}] [G loss: {np.mean(dis_and_gen_losses)}]\\n\")\n",
        "        \n",
        "          # save weights\n",
        "          if (epoch+1) % 5 == 0:\n",
        "              save_all_weights(dis, gen, epoch, int(np.mean(dis_and_gen_losses)))\n",
        "          # save models to resume training\n",
        "          if (epoch+1) % 5 == 0:\n",
        "              save_models(dis, dis_and_gen)         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-26T19:33:14.866467Z",
          "iopub.status.busy": "2020-08-26T19:33:14.865553Z",
          "iopub.status.idle": "2020-08-27T03:48:23.149262Z",
          "shell.execute_reply": "2020-08-27T03:48:23.150575Z"
        },
        "id": "Ghy8PVvcKGC4",
        "papermill": {
          "duration": 29708.576607,
          "end_time": "2020-08-27T03:48:23.150803",
          "exception": false,
          "start_time": "2020-08-26T19:33:14.574196",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "train(32, 50)#, load=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vweFGRTyzfNl"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Metrics\n",
        "Mean Squared Error\n",
        "\n",
        "SSIM measures the quality of the images taking as reference the original"
      ],
      "metadata": {
        "id": "ObnYvvkaCgsD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxXnxiL4vTVF"
      },
      "source": [
        "def MSE(img1, img2):\n",
        "    return np.mean( (img1/255. - img2/255.) ** 2 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrZD0RwXNJDT",
        "papermill": {
          "duration": 0.406439,
          "end_time": "2020-08-27T03:48:23.982142",
          "exception": false,
          "start_time": "2020-08-27T03:48:23.575703",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def test(batch_size):\n",
        "\ty_test, x_test = load_data(testX, testX_blur)\n",
        "\tgen = generator_model()\n",
        "\tgen.load_weights('/content/gdrive/My Drive/Colab Notebooks/weights/14/generator_600_3.h5')\n",
        "\tgenerated_images = gen.predict(x=x_test, batch_size=batch_size)\n",
        "\tgenerated = np.array([deprocess_image(img) for img in generated_images])\n",
        "\tx_test = deprocess_image(x_test)\n",
        "\ty_test = deprocess_image(y_test)\n",
        "\n",
        "\tssim = 0\n",
        "\tmse = 0\n",
        "\n",
        "\tfor i in range(generated_images.shape[0]):\n",
        "\t\ty = y_test[i, :, :, :]\n",
        "\t\tx = x_test[i, :, :, :]\n",
        "\t\timg = generated[i, :, :, :]\n",
        "\n",
        "        # randomly save 5% of tested images \n",
        "\t\tif not os.path.exists(\"/content/gdrive/My Drive/Colab Notebooks/results\"):\n",
        "\t\t\tos.makedirs(\"/content/gdrive/My Drive/Colab Notebooks/results\")\n",
        "\t\tif (np.random.random()*100) < 5:\n",
        "\t\t\toutput = np.concatenate((y, x, img), axis=1)\n",
        "\t\t\tim = Image.fromarray(output.astype(np.uint8))\n",
        "\t\t\tim.save('/content/gdrive/My Drive/Colab Notebooks/results/result{}.png'.format(i))\n",
        "\n",
        "\t\t# metrics\n",
        "\t\tssim += structural_similarity(y, img, multichannel=True)\n",
        "\t\tmse += MSE(y, img)\n",
        "\n",
        "\tavg_ssim = ssim / generated_images.shape[0]\n",
        "\tavg_mse = mse / generated_images.shape[0]\n",
        "\n",
        "\tprint('SSIM: {} \\n'.format(avg_ssim))\n",
        "\tprint('MSE: {} \\n'.format(avg_mse))\n",
        "\twith open('/content/gdrive/My Drive/Colab Notebooks/log.txt', 'a+') as f:\n",
        "\t\tf.write('SSIM: {} \\n'.format(avg_ssim))\n",
        "\t\tf.write('MSE: {} \\n'.format(avg_mse))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test local to test without connecting to Drive"
      ],
      "metadata": {
        "id": "cXmV95L7d7Am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_local(batch_size):\n",
        "  \ty_test, x_test = load_data(testX, testX_blur)\n",
        "\tgen = generator_model()\n",
        "\tgen.load_weights('generator_600_3.h5')\n",
        "\tgenerated_images = gen.predict(x=x_test, batch_size=batch_size)\n",
        "\tgenerated = np.array([deprocess_image(img) for img in generated_images])\n",
        "\tx_test = deprocess_image(x_test)\n",
        "\ty_test = deprocess_image(y_test)\n",
        "\n",
        "\tssim = 0\n",
        "\tmse = 0\n",
        "\n",
        "\tfor i in range(generated_images.shape[0]):\n",
        "\t\ty = y_test[i, :, :, :]\n",
        "\t\tx = x_test[i, :, :, :]\n",
        "\t\timg = generated[i, :, :, :]\n",
        "    \n",
        "\t\t# metrics\n",
        "\t\tssim += structural_similarity(y, img, multichannel=True)\n",
        "\t\tmse += MSE(y, img)\n",
        "\n",
        "\tavg_ssim = ssim / generated_images.shape[0]\n",
        "\tavg_mse = mse / generated_images.shape[0]\n",
        "\n",
        "\tprint('SSIM: {} \\n'.format(avg_ssim))\n",
        "\tprint('MSE: {} \\n'.format(avg_mse))"
      ],
      "metadata": {
        "id": "sNEaSv4g_UeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz9XaKkUvc7I"
      },
      "source": [
        "#test(16)\n",
        "test_local(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results"
      ],
      "metadata": {
        "id": "aRmONGUfPjwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/My Drive/Colab Notebooks/logs/log.txt') as f:\n",
        "  lines = f.readlines()\n",
        "  lines = [line.rstrip() for line in lines]\n",
        "index_list = []\n",
        "dis_loss_history = []\n",
        "gen_loss_history = []\n",
        "for line in lines:\n",
        "  index = line[0:2].lstrip()\n",
        "  dis_loss = line.split('[')[1].split('D loss: ')[1][:-2]\n",
        "  gen_loss = line.split('[')[2].split('G loss: ')[1][:-2]\n",
        "  index_list.append(int(index)+1)\n",
        "  dis_loss_history.append(float(dis_loss))\n",
        "  gen_loss_history.append(float(gen_loss))"
      ],
      "metadata": {
        "id": "_m_TZ1sERoLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = np.array(index_list)\n",
        "y1 = np.array(dis_loss_history)\n",
        "y2 = np.array(gen_loss_history)\n",
        "\n",
        "plt.plot(x, y1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-pqQw82P5i20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x, y2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8MayFilG6oLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some results"
      ],
      "metadata": {
        "id": "fcXO8cfG9FB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "images_list = ['result1', 'result2', 'result3', 'result4']\n",
        "for img in images_list:\n",
        "  img_file = img + '.png'\n",
        "  image = cv2.imread(img_file)\n",
        "  plt.figure()\n",
        "  plt.imshow(image) \n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "mZvWieAf93aB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}